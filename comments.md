# Comments from team (Use vim to navigate) 

## Naveed 14:07:50 (Mli is done merging, team will need to fix within content.tex)

comments/cihr_proposal_17Feb2020_NJ.pdf

- L48 Just an addition example (not very important)

There are reports of bias against Chinese people in social media and in news reports. Could be cited here.
https://www.theguardian.com/uk-news/2020/feb/09/chinese-in-uk-report-shocking-levels-of-racism-after-coronavirus-outbreak 
https://www.vox.com/2020/2/7/21126758/coronavirus-xenophobia-racism-china-asians
https://www.theguardian.com/world/2020/jan/28/canada-chinese-community-battles-racist-backlash-amid-coronavirus-outbreak

- L59 more examples (I don't think we need) and I added text I think is useful in already (see mli comments)

- L90 trivial fill in the black, I added this already.

- L108 More detail about textual analysis I don't know how to add. I added the comment in content.tex. 

- L109 Suggest adding Mask and hanitizer sales data and how they are good in providing info on public response. (I know it is useful but I don't think we should mention or say it unless we know we can get the data). 

- L114 Naveed is not clear about the Dynamical modeling section and how it will link back with the other theme.

- 132 Deliverables: Software (This is section is currently blank). Describe what kind of software. I was envisioning a tool that runs on Twitter stream data and classifies tweets based on contents as well as significance in terms of influence ( how much it has potential to spread based on following network or influencer.  
See paper for classification of influencers. https://bmcpublichealth.biomedcentral.com/articles/10.1186/s12889-019-6747-8 


## Earn 16:22:33 (MLi is done with DE comments) 

comments/DEcomments.md

Flow diagram: Does the media not influence policymakers? 
They may not want to admit it, but I bet it does.  
Reality might contain a dashed arrow from Media to Policymaker.  
Evidence for such effects is something that the methodology could address perhaps.

Obviously the later sections and figure captions need a lot of attention.


## Hyeju 16:22:33 (MLi is done merging Hyeju's intext comments)

Textual analysis To investigate how information/misinformation travels
and how communication affects public responses (e.g., attitudes), we
will use state-of-the-art machine learning and natural language
processing (NLP) techniques. We have two directions. First, to
investigate how information travels, we plan to develop codebooks to
manually annotate random samples of articles/messages from scientific
papers, government recommendations, mass media and social media.
Codebooks will contain both themes and frames relevant to our
analysis. For example, correct or incorrect information
(misinformation or not?) will be annotated. Then, using the annotated
data as training data, supervised machine learning algorithms such as
logistic regression, Support Vector Machine, and neural network will
learn patterns of textual and content features to predict the
label(code?). Second, to study public responses, we will leverage NLP
techniques such as aspect-based sentiment analysis and topic modeling.
For example, ABSApp [ref], a state-of-the-art aspect-based sentiment
extraction tool, allows extracting important aspects of the target(?)
situation and detecting sentiment towards the aspects, with relatively
less human involvement. Latent Dirichlet Allocation (LDA) and its
variants, popularly used topic modeling techniques, help identify
topics in large texts. These approaches will allow us to perform a
large scale study (using large data). For all the textual analysis
processes, computer scientists will work collaboratively with coders
and subject-matter experts to build codebooks that are consistent with
study aims, and to interpret findings from applying AI algorithms. The
findings would be shared with public-health practitioners to assist
with counter-messaging strategies.


